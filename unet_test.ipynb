{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System tools\n",
    "import scipy.misc\n",
    "import random\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Pytorch\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "# Image I/O\n",
    "import cv2\n",
    "import PIL\n",
    "from  matplotlib import pyplot as plt\n",
    "\n",
    "# Analysis\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_and_create_folder(directory):\n",
    "    try:\n",
    "        os.stat(directory)\n",
    "        print ('folder: ', directory, 'exits, do you want to remove it')\n",
    "    except:\n",
    "        os.mkdir(directory)\n",
    "        print ('create ', directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNet train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_IMG_SIZE = (480, 640)             # HEIGHT, WIDTH\n",
    "BATCH_SIZE   = 5\n",
    "NUM_EPOCHS   = 1000\n",
    "NUM_WROKERS  = 4\n",
    "LR           = 1e-3\n",
    "MOMENTUM     = 0\n",
    "WEIGHT_DECAY = 1e-5\n",
    "STEP_SIZE    = 50\n",
    "GAMMA        = 0.5\n",
    "DATASET_ROOT = \"./shoes_dataset_folder\"\n",
    "MODELS_ROOT  = \"./models\"\n",
    "CLASSES = [\"background\", \"right_shoes\", \"left_shoes\"]    # classes with 'background' element\n",
    "\n",
    "MASKS_DIR    = os.path.join(DATASET_ROOT, \"masks\")\n",
    "LABELS_DIR   = os.path.join(DATASET_ROOT, \"labels\")\n",
    "IMAGES_DIR   = os.path.join(DATASET_ROOT, \"images\")\n",
    "if not os.path.isdir(MODELS_ROOT):\n",
    "    os.mkdir(MODELS_ROOT)\n",
    "NUM_CLASSES = len(CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = pd.read_csv(os.path.join(DATASET_ROOT, \"train.csv\"))\n",
    "data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataset_csv_file, phase):\n",
    "        \n",
    "        self.data_list = pd.read_csv(dataset_csv_file)\n",
    "        \n",
    "        print(\"********** Dataset Info start **********\\n\")\n",
    "        print(\"Source: \" + dataset_csv_file)\n",
    "        print(\"Classes: {}\".format(CLASSES))\n",
    "        print(\"Amount of data: {}\".format(len(self.data_list)))\n",
    "        print(\"\\n*********** Dataset Info end ***********\\n\")\n",
    "        \n",
    "        self.data_transform = transforms.Compose([ \n",
    "                                transforms.Resize(INPUT_IMG_SIZE), \\\n",
    "                                transforms.ToTensor(), \\\n",
    "                                transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                                     std=[0.229, 0.224, 0.225])\n",
    "                                ])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_path   = self.data_list.iloc[index, 0]\n",
    "        mask_path    = self.data_list.iloc[index, 1]\n",
    "        \n",
    "        # Read image\n",
    "        image_raw = self.default_loader(os.path.join(DATASET_ROOT, image_path))\n",
    "        input_image = self.data_transform(image_raw)\n",
    "        # Read mask\n",
    "        # mask_raw = PIL_Image.open(mask_path).convert('LA')\n",
    "        mask_raw = cv2.imread(os.path.join(DATASET_ROOT, mask_path), cv2.IMREAD_GRAYSCALE)\n",
    "        mask_raw = cv2.resize(mask_raw, (INPUT_IMG_SIZE[1], INPUT_IMG_SIZE[0]))\n",
    "        mask_each_classes = torch.zeros(NUM_CLASSES, INPUT_IMG_SIZE[0], INPUT_IMG_SIZE[1])\n",
    "        for i in range(NUM_CLASSES):\n",
    "            mask_each_classes[i][mask_raw == i] = 1\n",
    "        # batch = {'input': input_image, 'target': mask_each_classes, 'mask_raw':mask_raw, 'image_raw': image_raw}\n",
    "        batch = {'input': input_image, 'target': mask_each_classes}\n",
    "        return batch\n",
    "    \n",
    "    def pil_loader(self, path):\n",
    "        with open(path, \"rb\") as f:\n",
    "            with PIL.Image.open(f) as img:\n",
    "                return img.convert(\"RGB\")\n",
    "\n",
    "    def accimage_loader(self, path):\n",
    "        try:\n",
    "            return accimage.Image(path)\n",
    "        except IOError:\n",
    "            # Potentially a decoding problem, fall back to PIL.Image\n",
    "            return pil_loader(path)\n",
    "\n",
    "    def default_loader(self, path):\n",
    "        if torchvision.get_image_backend() == \"accimage\":\n",
    "            return self.accimage_loader(path)\n",
    "        else:\n",
    "            return self.pil_loader(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Training data loader\n",
    "train_csv_path   = os.path.join(DATASET_ROOT, \"train.csv\")\n",
    "train_dataset    = CustomDataset(dataset_csv_file=train_csv_path, phase=\"train\")\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WROKERS)\n",
    "\n",
    "# Testing data loader\n",
    "test_csv_path   = os.path.join(DATASET_ROOT, \"test.csv\")\n",
    "test_dataset    = CustomDataset(dataset_csv_file=test_csv_path, phase='test')\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=4, num_workers=1)\n",
    "dataiter = iter(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "model = smp.Unet('resnet18', classes=NUM_CLASSES, activation='softmax', encoder_weights='imagenet')\n",
    "model.cuda()\n",
    "\n",
    "# define loss function\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=LR, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=STEP_SIZE, gamma=GAMMA) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, scheduler, loss_list, model_name):\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        model.train()\n",
    "        configs    = \"FCN_{}_batch{}_epoch{}_RMSprop_lr{}\".format(model_name, BATCH_SIZE, epoch, LR)\n",
    "        model_path = os.path.join(MODELS_ROOT, configs)\n",
    "        \n",
    "        for index, batch in enumerate(train_dataloader):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if torch.cuda.is_available():\n",
    "                inputs = batch['input'].cuda()\n",
    "                targets = batch['target'].cuda()\n",
    "            else:\n",
    "                inputs, targets = batch['X'], batch['Y']\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "            if index % 10 == 0:\n",
    "                print(\"epoch{}, iter{}, loss: {}\".format(epoch, index, loss))\n",
    "                # print(loss)\n",
    "  \n",
    "        scheduler.step()\n",
    "        loss_list.append(loss)\n",
    "        print(\"==== Finish epoch {} ====\".format(epoch))\n",
    "        if index % 50 == 0:\n",
    "            torch.save(model.state_dict(), model_path + '.pkl')\n",
    "        # val(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_list = []\n",
    "train(model, optimizer, scheduler, loss_list, model_name=\"resnet18\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
